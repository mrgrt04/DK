{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW06 (S06-hw-dataset-03)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    ConfusionMatrixDisplay,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "DATA_PATH = Path(\"data\") / \"S06-hw-dataset-03.csv\"\n",
        "\n",
        "\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id       f01       f02       f03       f04       f05       f06       f07  \\\n",
            "0   1 -2.721419  0.652294  1.867234 -0.245331 -0.241182 -0.195509  1.180193   \n",
            "1   2 -4.191520 -0.647731 -0.881929 -0.968159  3.530725 -4.858592  0.240979   \n",
            "2   3 -0.582739  0.415128 -4.205613 -0.320853  0.313570 -2.655451  2.215387   \n",
            "3   4 -1.766082  1.253523  1.610804  0.466067  3.837868 -3.564073 -1.831031   \n",
            "4   5 -2.157834 -1.361285 -0.917199  0.937285  0.408551 -0.062032 -0.480196   \n",
            "\n",
            "        f08       f09  ...       f20       f21       f22       f23       f24  \\\n",
            "0 -0.724816  1.804165  ...  0.042851 -0.153232  1.566167 -1.516125 -1.586857   \n",
            "1 -0.714017  0.285769  ... -1.170056  0.631661  1.277915 -0.464432  1.927986   \n",
            "2  1.492222 -0.516727  ...  0.083281 -0.757912  5.672669 -0.283472  0.275362   \n",
            "3  1.066265 -0.198636  ... -0.674648  1.780285 -4.718432  0.711573  1.705610   \n",
            "4 -0.554454 -1.026434  ... -0.096277  0.212875  1.710699  2.476220  0.669305   \n",
            "\n",
            "        f25       f26       f27       f28  target  \n",
            "0 -3.998937 -1.308459  2.155125  1.992519       0  \n",
            "1  6.034154  0.149833  4.861592 -3.547303       0  \n",
            "2 -0.988055  0.940883 -3.050749 -0.703865       1  \n",
            "3  6.474380 -1.690537  8.687735 -2.799399       0  \n",
            "4  3.166072 -0.718493  3.630457  0.083986       0  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15000 entries, 0 to 14999\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   id      15000 non-null  int64  \n",
            " 1   f01     15000 non-null  float64\n",
            " 2   f02     15000 non-null  float64\n",
            " 3   f03     15000 non-null  float64\n",
            " 4   f04     15000 non-null  float64\n",
            " 5   f05     15000 non-null  float64\n",
            " 6   f06     15000 non-null  float64\n",
            " 7   f07     15000 non-null  float64\n",
            " 8   f08     15000 non-null  float64\n",
            " 9   f09     15000 non-null  float64\n",
            " 10  f10     15000 non-null  float64\n",
            " 11  f11     15000 non-null  float64\n",
            " 12  f12     15000 non-null  float64\n",
            " 13  f13     15000 non-null  float64\n",
            " 14  f14     15000 non-null  float64\n",
            " 15  f15     15000 non-null  float64\n",
            " 16  f16     15000 non-null  float64\n",
            " 17  f17     15000 non-null  float64\n",
            " 18  f18     15000 non-null  float64\n",
            " 19  f19     15000 non-null  float64\n",
            " 20  f20     15000 non-null  float64\n",
            " 21  f21     15000 non-null  float64\n",
            " 22  f22     15000 non-null  float64\n",
            " 23  f23     15000 non-null  float64\n",
            " 24  f24     15000 non-null  float64\n",
            " 25  f25     15000 non-null  float64\n",
            " 26  f26     15000 non-null  float64\n",
            " 27  f27     15000 non-null  float64\n",
            " 28  f28     15000 non-null  float64\n",
            " 29  target  15000 non-null  int64  \n",
            "dtypes: float64(28), int64(2)\n",
            "memory usage: 3.4 MB\n",
            "None\n",
            "target\n",
            "0    0.542533\n",
            "1    0.302333\n",
            "2    0.155133\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df[\"target\"].value_counts(normalize=True))\n",
        "\n",
        "X = df.drop(columns=[\"target\"])\n",
        "if \"id\" in X.columns:\n",
        "    X = X.drop(columns=[\"id\"])\n",
        "y = df[\"target\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target\n",
            "0    0.542578\n",
            "1    0.302311\n",
            "2    0.155111\n",
            "Name: proportion, dtype: float64\n",
            "target\n",
            "0    0.5424\n",
            "1    0.3024\n",
            "2    0.1552\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DummyClassifier': {'accuracy': 0.5424,\n",
              "  'f1': 0.2344398340248963,\n",
              "  'roc_auc': np.float64(0.5)},\n",
              " 'LogisticRegression': {'accuracy': 0.72,\n",
              "  'f1': 0.6632634159041243,\n",
              "  'roc_auc': np.float64(0.8467788482997881)}}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_metrics(model, X_test, y_test, is_multiclass=False):\n",
        "    preds = model.predict(X_test)\n",
        "    metrics = {\"accuracy\": accuracy_score(y_test, preds)}\n",
        "    if is_multiclass:\n",
        "        metrics[\"f1\"] = f1_score(y_test, preds, average=\"macro\")\n",
        "    else:\n",
        "        metrics[\"f1\"] = f1_score(y_test, preds)\n",
        "\n",
        "    roc_auc = None\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        proba = model.predict_proba(X_test)\n",
        "        if is_multiclass:\n",
        "            roc_auc = roc_auc_score(y_test, proba, multi_class=\"ovr\")\n",
        "        else:\n",
        "            # положительный класс – 1\n",
        "            roc_auc = roc_auc_score(y_test, proba[:, 1])\n",
        "    metrics[\"roc_auc\"] = roc_auc\n",
        "    return metrics\n",
        "\n",
        "is_multiclass = y.nunique() > 2\n",
        "\n",
        "metrics = {}\n",
        "\n",
        "dummy = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
        "dummy.fit(X_train, y_train)\n",
        "metrics[\"DummyClassifier\"] = compute_metrics(dummy, X_test, y_test, is_multiclass)\n",
        "\n",
        "logreg = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(max_iter=1000, random_state=42)),\n",
        "])\n",
        "logreg.fit(X_train, y_train)\n",
        "metrics[\"LogisticRegression\"] = compute_metrics(logreg, X_test, y_test, is_multiclass)\n",
        "\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DecisionTreeClassifier': {'scoring': 'f1_macro',\n",
              "  'best_score_cv': 0.707935929615873,\n",
              "  'best_params': {'ccp_alpha': 0.0,\n",
              "   'max_depth': 12,\n",
              "   'max_leaf_nodes': None,\n",
              "   'min_impurity_decrease': 0.0001,\n",
              "   'min_samples_leaf': 5,\n",
              "   'min_samples_split': 2}},\n",
              " 'RandomForestClassifier': {'scoring': 'f1_macro',\n",
              "  'best_score_cv': 0.8313306626046147,\n",
              "  'best_params': {'max_depth': None,\n",
              "   'max_features': 'sqrt',\n",
              "   'min_samples_leaf': 1,\n",
              "   'n_estimators': 150}},\n",
              " 'GradientBoostingClassifier': {'scoring': 'f1_macro',\n",
              "  'best_score_cv': 0.7829266044722577,\n",
              "  'best_params': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}}}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scoring = \"f1_macro\" if is_multiclass else \"roc_auc\"\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "searches = {}\n",
        "models = {}\n",
        "\n",
        "# Decision Tree (контроль сложности)\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_grid = {\n",
        "    # ограничение глубины/структуры\n",
        "    \"max_depth\": [None, 3, 5, 8, 12],\n",
        "    \"max_leaf_nodes\": [None, 15, 31, 63],\n",
        "    # ограничение разбиений\n",
        "    \"min_samples_split\": [2, 10, 30],\n",
        "    \"min_samples_leaf\": [1, 5, 15],\n",
        "    # порог улучшения и пост-обрезка\n",
        "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
        "    \"ccp_alpha\": [0.0, 1e-4, 1e-3],\n",
        "}\n",
        "\n",
        "tree_search = GridSearchCV(\n",
        "    tree,\n",
        "    tree_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "tree_search.fit(X_train, y_train)\n",
        "searches[\"DecisionTreeClassifier\"] = tree_search\n",
        "models[\"DecisionTreeClassifier\"] = tree_search.best_estimator_\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_grid = {\n",
        "    \"n_estimators\": [150],\n",
        "    \"max_depth\": [None, 10],\n",
        "    \"min_samples_leaf\": [1, 5],\n",
        "    \"max_features\": [\"sqrt\"],\n",
        "}\n",
        "\n",
        "rf_search = GridSearchCV(\n",
        "    rf,\n",
        "    rf_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "rf_search.fit(X_train, y_train)\n",
        "searches[\"RandomForestClassifier\"] = rf_search\n",
        "models[\"RandomForestClassifier\"] = rf_search.best_estimator_\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_grid = {\n",
        "    \"n_estimators\": [100],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"max_depth\": [2, 3],\n",
        "}\n",
        "\n",
        "gb_search = GridSearchCV(\n",
        "    gb,\n",
        "    gb_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "gb_search.fit(X_train, y_train)\n",
        "searches[\"GradientBoostingClassifier\"] = gb_search\n",
        "models[\"GradientBoostingClassifier\"] = gb_search.best_estimator_\n",
        "\n",
        "# краткое резюме по CV\n",
        "search_summaries = {\n",
        "    name: {\n",
        "        \"scoring\": scoring,\n",
        "        \"best_score_cv\": float(search.best_score_),\n",
        "        \"best_params\": search.best_params_,\n",
        "    }\n",
        "    for name, search in searches.items()\n",
        "}\n",
        "\n",
        "search_summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ok'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\"ok\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'RandomForestClassifier'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Выбираем лучшую модель по CV (только train), без использования test\n",
        "best_model_name = max(search_summaries.items(), key=lambda kv: kv[1][\"best_score_cv\"])[0]\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "# Финальная оценка на test (используется только один раз)\n",
        "metrics_test = {\n",
        "    \"DummyClassifier\": metrics[\"DummyClassifier\"],\n",
        "    \"LogisticRegression\": metrics[\"LogisticRegression\"],\n",
        "    best_model_name: compute_metrics(best_model, X_test, y_test, is_multiclass),\n",
        "}\n",
        "\n",
        "with (ARTIFACTS_DIR / \"metrics_test.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics_test, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with (ARTIFACTS_DIR / \"search_summaries.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(search_summaries, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "best_model_meta = {\n",
        "    \"best_model_name\": best_model_name,\n",
        "    \"scoring\": scoring,\n",
        "    \"best_score_cv\": search_summaries[best_model_name][\"best_score_cv\"],\n",
        "    \"best_params\": search_summaries[best_model_name][\"best_params\"],\n",
        "}\n",
        "with (ARTIFACTS_DIR / \"best_model_meta.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(best_model_meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "best_model_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'done'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = models[best_model_name]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, ax=ax, colorbar=False)\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "fig.tight_layout()\n",
        "fig.savefig(ARTIFACTS_DIR / \"figures_confusion_matrix_from_nb.png\", dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "\"done\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'done'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=42)\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1][:15]\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.barh(range(len(indices)), importances[indices][::-1])\n",
        "plt.yticks(range(len(indices)), np.array(X.columns)[indices][::-1])\n",
        "plt.xlabel(\"Mean Importance (Permutation)\")\n",
        "plt.title(\"Top Features\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(ARTIFACTS_DIR / \"figures_permutation_importance_from_nb.png\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "\"done\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

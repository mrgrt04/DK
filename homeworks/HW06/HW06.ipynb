{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HW06 – (S06-hw-dataset-01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    ConfusionMatrixDisplay,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DATA_PATH = Path(\"data\") / \"S06-hw-dataset-01.csv\"\n",
        "ARTIFACTS_DIR = Path(\"artifacts\")\n",
        "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id     num01     num02     num03     num04     num05     num06     num07  \\\n",
            "0   1 -0.946058 -0.070313  1.824445 -2.754422  0.808865 -0.111094 -0.268950   \n",
            "1   2 -2.484027  0.739378  1.596908 -2.586479 -0.033225 -3.054412 -4.706908   \n",
            "2   3  1.522629  7.159635 -0.564903 -4.493110  1.623610  5.450187 -0.974595   \n",
            "3   4  0.463373 -1.073908  1.752813  0.362786  2.790872  4.082385  0.322283   \n",
            "4   5  3.188390 -4.701692 -0.689918 -0.448995  0.373821 -3.275363 -1.760931   \n",
            "\n",
            "      num08     num09  ...     num20     num21     num22     num23     num24  \\\n",
            "0 -3.078210  0.801275  ... -1.616515 -1.989464  1.407390 -0.218362  2.016052   \n",
            "1 -9.795169  0.145911  ... -1.727040 -0.583997  1.136761  0.285978 -0.310879   \n",
            "2 -5.189589  1.600591  ...  0.524408  2.022430  1.278358 -0.850547  0.847457   \n",
            "3  3.390984 -0.033929  ...  2.399834 -1.431576 -0.746987  0.049639  2.414689   \n",
            "4  0.923689  0.537345  ... -2.183407 -2.896590  2.440343 -1.097168  1.457323   \n",
            "\n",
            "   cat_contract  cat_region  cat_payment  tenure_months  target  \n",
            "0             0           2            3             33       0  \n",
            "1             2           2            2            102       1  \n",
            "2             1           0            2              3       0  \n",
            "3             1           0            1             50       0  \n",
            "4             1           2            3             81       0  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12000 entries, 0 to 11999\n",
            "Data columns (total 30 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             12000 non-null  int64  \n",
            " 1   num01          12000 non-null  float64\n",
            " 2   num02          12000 non-null  float64\n",
            " 3   num03          12000 non-null  float64\n",
            " 4   num04          12000 non-null  float64\n",
            " 5   num05          12000 non-null  float64\n",
            " 6   num06          12000 non-null  float64\n",
            " 7   num07          12000 non-null  float64\n",
            " 8   num08          12000 non-null  float64\n",
            " 9   num09          12000 non-null  float64\n",
            " 10  num10          12000 non-null  float64\n",
            " 11  num11          12000 non-null  float64\n",
            " 12  num12          12000 non-null  float64\n",
            " 13  num13          12000 non-null  float64\n",
            " 14  num14          12000 non-null  float64\n",
            " 15  num15          12000 non-null  float64\n",
            " 16  num16          12000 non-null  float64\n",
            " 17  num17          12000 non-null  float64\n",
            " 18  num18          12000 non-null  float64\n",
            " 19  num19          12000 non-null  float64\n",
            " 20  num20          12000 non-null  float64\n",
            " 21  num21          12000 non-null  float64\n",
            " 22  num22          12000 non-null  float64\n",
            " 23  num23          12000 non-null  float64\n",
            " 24  num24          12000 non-null  float64\n",
            " 25  cat_contract   12000 non-null  int64  \n",
            " 26  cat_region     12000 non-null  int64  \n",
            " 27  cat_payment    12000 non-null  int64  \n",
            " 28  tenure_months  12000 non-null  int64  \n",
            " 29  target         12000 non-null  int64  \n",
            "dtypes: float64(24), int64(6)\n",
            "memory usage: 2.7 MB\n",
            "None\n",
            "target\n",
            "0    0.676583\n",
            "1    0.323417\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df[\"target\"].value_counts(normalize=True))\n",
        "\n",
        "X = df.drop(columns=[\"target\"])\n",
        "if \"id\" in X.columns:\n",
        "    X = X.drop(columns=[\"id\"])\n",
        "y = df[\"target\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target\n",
            "0    0.676556\n",
            "1    0.323444\n",
            "Name: proportion, dtype: float64\n",
            "target\n",
            "0    0.676667\n",
            "1    0.323333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Dummy': {'accuracy': 0.6766666666666666, 'f1': 0.0, 'roc_auc': 0.5},\n",
              " 'LogisticRegression': {'accuracy': 0.8296666666666667,\n",
              "  'f1': 0.7146845337800112,\n",
              "  'roc_auc': 0.8789091463104972},\n",
              " 'DecisionTree': {'accuracy': 0.8566666666666667,\n",
              "  'f1': 0.7767393561786086,\n",
              "  'roc_auc': 0.8343354832156822},\n",
              " 'RandomForest': {'accuracy': 0.9306666666666666,\n",
              "  'f1': 0.8878101402373247,\n",
              "  'roc_auc': 0.9696805647250012},\n",
              " 'Boosting': {'accuracy': 0.9063333333333333,\n",
              "  'f1': 0.8446655610834716,\n",
              "  'roc_auc': 0.9582387892946016}}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "def compute_metrics(model, X_test, y_test, is_multiclass=False):\n",
        "    preds = model.predict(X_test)\n",
        "    metrics = {\"accuracy\": accuracy_score(y_test, preds)}\n",
        "\n",
        "    if is_multiclass:\n",
        "        metrics[\"f1\"] = f1_score(y_test, preds, average=\"macro\")\n",
        "    else:\n",
        "        metrics[\"f1\"] = f1_score(y_test, preds)\n",
        "\n",
        "    roc_auc = None\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        proba = model.predict_proba(X_test)\n",
        "        if is_multiclass:\n",
        "            roc_auc = roc_auc_score(y_test, proba, multi_class=\"ovr\")\n",
        "        else:\n",
        "            roc_auc = roc_auc_score(y_test, proba[:, 1])\n",
        "\n",
        "    metrics[\"roc_auc\"] = roc_auc\n",
        "    return metrics\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "is_multiclass = y.nunique() > 2\n",
        "\n",
        "metrics = {}\n",
        "\n",
        "# Dummy\n",
        "dummy = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
        "dummy.fit(X_train, y_train)\n",
        "metrics[\"Dummy\"] = compute_metrics(dummy, X_test, y_test, is_multiclass)\n",
        "\n",
        "# LogisticRegression\n",
        "logreg = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(max_iter=1000, random_state=42)),\n",
        "])\n",
        "logreg.fit(X_train, y_train)\n",
        "metrics[\"LogisticRegression\"] = compute_metrics(logreg, X_test, y_test, is_multiclass)\n",
        "\n",
        "# DecisionTree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "metrics[\"DecisionTree\"] = compute_metrics(dt, X_test, y_test, is_multiclass)\n",
        "\n",
        "# RandomForest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "metrics[\"RandomForest\"] = compute_metrics(rf, X_test, y_test, is_multiclass)\n",
        "\n",
        "# Boosting\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "metrics[\"Boosting\"] = compute_metrics(gb, X_test, y_test, is_multiclass)\n",
        "\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'DecisionTreeClassifier': DecisionTreeClassifier(min_samples_leaf=15, random_state=42),\n",
              " 'RandomForestClassifier': RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42),\n",
              " 'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42)}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scoring = \"f1_macro\" if is_multiclass else \"roc_auc\"\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Для выбора модели используем только CV на train, test не трогаем.\n",
        "searches = {}\n",
        "models = {}\n",
        "cv_scores = {}\n",
        "\n",
        "# Decision Tree: контроль сложности\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_grid = {\n",
        "    # ограничение структуры\n",
        "    \"max_depth\": [None, 3, 5, 8, 12],\n",
        "    \"max_leaf_nodes\": [None, 15, 31, 63],\n",
        "    # ограничение разбиений\n",
        "    \"min_samples_split\": [2, 10, 30],\n",
        "    \"min_samples_leaf\": [1, 5, 15],\n",
        "    # порог улучшения и пост-обрезка\n",
        "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
        "    \"ccp_alpha\": [0.0, 1e-4, 1e-3],\n",
        "}\n",
        "\n",
        "tree_search = GridSearchCV(\n",
        "    tree,\n",
        "    tree_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "tree_search.fit(X_train, y_train)\n",
        "searches[\"DecisionTreeClassifier\"] = tree_search\n",
        "models[\"DecisionTreeClassifier\"] = tree_search.best_estimator_\n",
        "cv_scores[\"DecisionTreeClassifier\"] = tree_search.best_score_\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_grid = {\n",
        "    \"n_estimators\": [150],\n",
        "    \"max_depth\": [None, 10],\n",
        "    \"min_samples_leaf\": [1, 5],\n",
        "    \"max_features\": [\"sqrt\"],\n",
        "}\n",
        "\n",
        "rf_search = GridSearchCV(\n",
        "    rf,\n",
        "    rf_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "rf_search.fit(X_train, y_train)\n",
        "searches[\"RandomForestClassifier\"] = rf_search\n",
        "models[\"RandomForestClassifier\"] = rf_search.best_estimator_\n",
        "cv_scores[\"RandomForestClassifier\"] = rf_search.best_score_\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb_grid = {\n",
        "    \"n_estimators\": [100],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"max_depth\": [2, 3],\n",
        "}\n",
        "\n",
        "gb_search = GridSearchCV(\n",
        "    gb,\n",
        "    gb_grid,\n",
        "    scoring=scoring,\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        ")\n",
        "gb_search.fit(X_train, y_train)\n",
        "searches[\"GradientBoostingClassifier\"] = gb_search\n",
        "models[\"GradientBoostingClassifier\"] = gb_search.best_estimator_\n",
        "cv_scores[\"GradientBoostingClassifier\"] = gb_search.best_score_\n",
        "\n",
        "# Резюме по CV\n",
        "search_summaries = {\n",
        "    name: {\n",
        "        \"scoring\": scoring,\n",
        "        \"best_score_cv\": float(search.best_score_),\n",
        "        \"best_params\": search.best_params_,\n",
        "    }\n",
        "    for name, search in searches.items()\n",
        "}\n",
        "\n",
        "best_model_name = max(cv_scores.items(), key=lambda item: item[1])[0]\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Dummy': {'accuracy': 0.6766666666666666, 'f1': 0.0, 'roc_auc': 0.5},\n",
              " 'LogisticRegression': {'accuracy': 0.8296666666666667,\n",
              "  'f1': 0.7146845337800112,\n",
              "  'roc_auc': 0.8789091463104972},\n",
              " 'DecisionTree': {'accuracy': 0.8566666666666667,\n",
              "  'f1': 0.7767393561786086,\n",
              "  'roc_auc': 0.8343354832156822},\n",
              " 'RandomForest': {'accuracy': 0.9306666666666666,\n",
              "  'f1': 0.8878101402373247,\n",
              "  'roc_auc': 0.9696805647250012},\n",
              " 'Boosting': {'accuracy': 0.9063333333333333,\n",
              "  'f1': 0.8446655610834716,\n",
              "  'roc_auc': 0.9582387892946016},\n",
              " 'RandomForestClassifier': {'accuracy': 0.9313333333333333,\n",
              "  'f1': 0.8890086206896551,\n",
              "  'roc_auc': 0.9696493321822152}}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics[best_model_name] = compute_metrics(best_model, X_test, y_test, is_multiclass)\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'RandomForestClassifier'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with (ARTIFACTS_DIR / \"metrics_test.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "best_model_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'done'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = models[best_model_name]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, ax=ax, colorbar=False)\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "fig.tight_layout()\n",
        "fig.savefig(ARTIFACTS_DIR / \"figures_confusion_matrix_from_nb.png\", dpi=150)\n",
        "plt.close(fig)\n",
        "\n",
        "if hasattr(best_model, \"predict_proba\") and not is_multiclass:\n",
        "    proba = best_model.predict_proba(X_test)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "    roc_auc = roc_auc_score(y_test, proba)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(fpr, tpr, label=f\"ROC AUC = {roc_auc:.4f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ARTIFACTS_DIR / \"figures_roc_curve_from_nb.png\", dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\"done\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'done'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = permutation_importance(best_model, X_test, y_test, n_repeats=5, random_state=42)\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1][:15]\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.barh(range(len(indices)), importances[indices][::-1])\n",
        "plt.yticks(range(len(indices)), np.array(X.columns)[indices][::-1])\n",
        "plt.xlabel(\"Mean Importance (Permutation)\")\n",
        "plt.title(\"Top Features\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(ARTIFACTS_DIR / \"figures_permutation_importance_from_nb.png\", dpi=150)\n",
        "plt.close()\n",
        "\n",
        "\"done\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

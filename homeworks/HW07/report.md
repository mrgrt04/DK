# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4:

- Dataset A — `S07-hw-dataset-01.csv`
- Dataset B — `S07-hw-dataset-02.csv`
- Dataset C — `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (N строк, M + 1 столбец, включая `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - разные масштабы признаков
  - без масштабирования distance-based методы работают некорректно

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (N строк, M + 1 столбец, включая `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - нелинейная структура данных
  - наличие выбросов и шума
  - кластеры плохо описываются KMeans

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (N строк, M + 1 столбец, включая `sample_id`)
- Признаки: все признаки числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - кластеры разной плотности
  - присутствует фоновый шум

## 2. Protocol

Использовался следующий честный unsupervised-протокол:

- Препроцессинг:
  - столбец `sample_id` удалялся из признаков
  - все признаки числовые
  - применялся `StandardScaler`
- Поиск гиперпараметров:
  - **KMeans**: перебор `k = 2..12`, фиксированы `random_state=42`, `n_init=20`
  - **DBSCAN**: `min_samples ∈ {3,5,8,12}`, `eps` подбирался по эвристике k-distance
  - лучший вариант выбирался по максимуму silhouette
- Метрики:
  - Silhouette score
  - Davies–Bouldin index
  - Calinski–Harabasz index
  - для DBSCAN метрики считались по non-noise точкам (`label != -1`)
- Визуализация:
  - PCA(2D) scatter для лучшего решения на каждом датасете

## 3. Models

Для каждого датасета сравнивались следующие модели:

- **KMeans**
  - подбор `k = 2..12`
  - фиксированы `random_state=42`, `n_init=20`
- **DBSCAN**
  - подбор `eps`
  - подбор `min_samples`
  - анализ доли шума (`label = -1`)

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, оптимальное значение `k`
- Метрики (silhouette / DB / CH): значения максимальны среди протестированных
- DBSCAN использовался, но показал худший silhouette
- Коротко: датасет хорошо подходит для KMeans после масштабирования

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, оптимальные `eps` и `min_samples`
- Метрики (silhouette / DB / CH): DBSCAN превосходит KMeans
- Доля шума: присутствует, но допустима
- Коротко: нелинейная структура и выбросы делают DBSCAN предпочтительным

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (как более стабильный вариант)
- Метрики (silhouette / DB / CH): умеренные значения
- DBSCAN создаёт слишком много шума
- Коротко: разная плотность кластеров усложняет работу DBSCAN

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans ломается при нелинейной структуре и выбросах
- DBSCAN выигрывает при наличии шума и сложной геометрии кластеров
- Масштабирование признаков критично для обоих алгоритмов

### 5.2 Устойчивость (обязательно для одного датасета)

- Проведено 5 запусков KMeans с разными `random_state`
- Разбиения кластеров практически совпадали
- Вывод: решение устойчиво, локальные минимумы несущественны

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через визуализацию PCA(2D)
- Кластеры различаются по плотности и положению в пространстве признаков
- Разделение выглядит логичным и интерпретируемым

## 6. Conclusion

- Масштабирование обязательно для кластеризации
- Silhouette — удобная, но не универсальная метрика
- KMeans эффективен для компактных кластеров
- DBSCAN полезен при шуме и выбросах
- Выбор алгоритма зависит от структуры данных
- В unsupervised-задачах важен честный протокол
